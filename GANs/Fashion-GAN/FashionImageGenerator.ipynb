{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc57ab97-4a07-427b-bb07-b7ecf75d615a",
   "metadata": {
    "id": "fc57ab97-4a07-427b-bb07-b7ecf75d615a",
    "tags": []
   },
   "source": [
    "<h1>Imports and Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YeAM3NzPEzWq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YeAM3NzPEzWq",
    "outputId": "9afd2b38-cd5b-410a-a052-87f6e7f5d3fa"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d7d4d-713a-4e88-a704-7687e10a249d",
   "metadata": {
    "id": "0e8d7d4d-713a-4e88-a704-7687e10a249d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install tensorflow matplotlib tensorflow-datasets ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e8783-f9d5-4699-a166-14b719a6617b",
   "metadata": {
    "id": "b90e8783-f9d5-4699-a166-14b719a6617b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gbWk329BE6Za",
   "metadata": {
    "id": "gbWk329BE6Za",
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.chdir('/content/gdrive/MyDrive/Colab Notebooks/GANs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337705c-347b-4652-a9d0-bc7fd27390da",
   "metadata": {
    "id": "2337705c-347b-4652-a9d0-bc7fd27390da",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#gets the GPUs on the machine you are using\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "#looping through all the GPUs and setting memory gowth (so tensforlow wil allocate the memory it needs and not over use VRAM)\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2f8bf0-a563-4732-879a-7b1e321d3d85",
   "metadata": {
    "id": "7f2f8bf0-a563-4732-879a-7b1e321d3d85",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Fashion Dataset\n",
    "data = tfds.load('fashion_mnist', split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8676cd6-68aa-4ccd-933c-b8632fe7cc53",
   "metadata": {
    "id": "a8676cd6-68aa-4ccd-933c-b8632fe7cc53",
    "tags": []
   },
   "source": [
    "<h1>Data Vizualisation and Data Pipeline</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a37e3e7-2077-4e36-ab8f-dd7566e673cd",
   "metadata": {
    "id": "1a37e3e7-2077-4e36-ab8f-dd7566e673cd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Setup Connection to data iterator\n",
    "data_iterator = data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc59dac-9902-4cb1-9333-480bd7985b84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5bc59dac-9902-4cb1-9333-480bd7985b84",
    "outputId": "38f1d16b-a0c4-4d5b-aab0-c65216dcee89",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Getting data out of iterator\n",
    "data_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f8b968-d78c-4c74-932a-8661d86964b4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "id": "37f8b968-d78c-4c74-932a-8661d86964b4",
    "outputId": "a4196232-771d-487a-e9ac-041e3f709545",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for i in range(4):\n",
    "    batch = data_iterator.next()\n",
    "    ax[i].imshow(np.squeeze(batch['image']))\n",
    "    ax[i].title.set_text(batch['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f4d20-02ad-43f9-9bbd-95c7eb342827",
   "metadata": {
    "id": "ae6f4d20-02ad-43f9-9bbd-95c7eb342827",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Scaling and returning images\n",
    "#Will Scale image between 0 and 1 to train model faster\n",
    "def scale_image(img):\n",
    "    image = img['image']\n",
    "    return image/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a18a31c-110e-4ab5-9444-684b19131205",
   "metadata": {
    "id": "4a18a31c-110e-4ab5-9444-684b19131205",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Steps when creating a Tensorflow Pipeline\n",
    "#1)map - map a function to dataset\n",
    "#2)cache - Cache dataset for that batch\n",
    "#3)shuffle - Shuffle dataset\n",
    "#4)batch - set betch size e.g. batch(128) will be 128 images per sample\n",
    "#5)prefetch - Reduced the likelihood of bottlenecking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa5199-a345-4dad-b730-38381288938b",
   "metadata": {
    "id": "f8aa5199-a345-4dad-b730-38381288938b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data.map(scale_image)\n",
    "data = data.cache()\n",
    "data = data.shuffle(60000)\n",
    "data = data.batch(128)\n",
    "data= data.prefetch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93ffcf3-c739-492c-b574-525d28f28b80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a93ffcf3-c739-492c-b574-525d28f28b80",
    "outputId": "45c49e33-92c8-4464-9a15-c543e80b48b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.as_numpy_iterator().next().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95879602-2a5e-48a7-bc30-3a26e7d1e167",
   "metadata": {
    "id": "95879602-2a5e-48a7-bc30-3a26e7d1e167",
    "tags": []
   },
   "source": [
    "<h1>Model</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9bfe56-80f7-46fd-8e24-72f4abfff0d8",
   "metadata": {
    "id": "ba9bfe56-80f7-46fd-8e24-72f4abfff0d8",
    "tags": []
   },
   "source": [
    "<p>Building two models - Generator and Discriminator</p>\n",
    "<p>Generator will generate the images</p>\n",
    "<p>Discriminator will decide whether input image (from Generator) is real or fake</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f2db13-a124-4056-bc0f-0cb140062a19",
   "metadata": {
    "id": "f8f2db13-a124-4056-bc0f-0cb140062a19",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = Sequential()\n",
    "\n",
    "    #Takes in random values and reshapes it to 7x7x128\n",
    "    #Beginnings of a generated image\n",
    "    model.add(Dense(7*7*128, input_dim=128))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "\n",
    "    #Upsampling block 1\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, 5, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    #Upsampling block 2\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, 5, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    #Convolutional block 1\n",
    "    model.add(Conv2D(128, 4, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    #Convolutional block 2\n",
    "    model.add(Conv2D(128, 4, padding='same'))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "\n",
    "    #Conv layer to get to one channel\n",
    "    model.add(Conv2D(1, 4, padding='same', activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb87a76-d720-4ad7-8273-987f845f4cd7",
   "metadata": {
    "id": "4cb87a76-d720-4ad7-8273-987f845f4cd7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = build_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bca72b-aad3-42f5-acdc-9cc4ffbd35cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32bca72b-aad3-42f5-acdc-9cc4ffbd35cf",
    "outputId": "23a1b7ce-34b5-4f97-bb1e-7951f573cb01",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576aa31-6623-4af2-b93c-4b117bc68ca6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d576aa31-6623-4af2-b93c-4b117bc68ca6",
    "outputId": "276c277d-e687-47da-cd9b-3e301aa8768f",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = generator.predict(np.random.randn(4,128,1))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4746db48-8bac-427b-b478-865a6e59a0ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "id": "4746db48-8bac-427b-b478-865a6e59a0ff",
    "outputId": "720e7814-800f-4424-941f-9874b8fc8b53",
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = generator.predict(np.random.randn(4,128,1))\n",
    "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
    "for i, img in enumerate(img):\n",
    "    batch = data_iterator.next()\n",
    "    ax[i].imshow(np.squeeze(img))\n",
    "    ax[i].title.set_text(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875f989-27aa-4ffe-a103-39cdc0b14ecc",
   "metadata": {
    "id": "c875f989-27aa-4ffe-a103-39cdc0b14ecc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "\n",
    "    #First Convolutional Block\n",
    "    model.add(Conv2D(32, 5, input_shape=(28, 28, 1)))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    #Second Convolutional Block\n",
    "    model.add(Conv2D(64, 5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    #Third Convolutional Block\n",
    "    model.add(Conv2D(128, 5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    #Fourth Convolutional Block\n",
    "    model.add(Conv2D(256, 5))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    #Flatten then pass to dense layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66926e9a-1daa-4b5f-be5a-8091cf2a040d",
   "metadata": {
    "id": "66926e9a-1daa-4b5f-be5a-8091cf2a040d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559e26c4-20b5-4a78-b36b-e7a18c927a40",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "559e26c4-20b5-4a78-b36b-e7a18c927a40",
    "outputId": "cbf7671b-d3d8-4cb7-9ffe-abf4963ec739",
    "tags": []
   },
   "outputs": [],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f077d-f964-449f-b708-8429d7cad933",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "392f077d-f964-449f-b708-8429d7cad933",
    "outputId": "388d90c3-399f-4a58-8862-98ca7b945fb5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#if img = generator.predict(np.random.randn(4,128,1)) -> img.shape = (4, 28, 28, 1)\n",
    "#then discriminator.predict(img)\n",
    "\n",
    "#However after plotting the images the shape is (28, 28, 1)), so we do:\n",
    "#discriminator.predict(np.expand_dims(img, 0))\n",
    "\n",
    "#Reset img\n",
    "\n",
    "img = generator.predict(np.random.randn(4,128,1))\n",
    "discriminator.predict(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef5030-a6dc-4f54-958e-7b958ee2a962",
   "metadata": {
    "id": "31ef5030-a6dc-4f54-958e-7b958ee2a962"
   },
   "source": [
    "<h1>Training Loop</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d2a2da-47c7-493a-ac7e-4662378a9850",
   "metadata": {
    "id": "98d2a2da-47c7-493a-ac7e-4662378a9850"
   },
   "source": [
    "<p>Typically when Training a Deep Neural network in tf you can create a model, then model.compile to add a loss function and optimizer and then do model.fit to fit the model to the data. However you can't do that in GANs because you have a generator and a discriminator that need to be trained side by side. So we are defining our own training loop</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f4978f-7e53-4d5d-acec-671749f4e149",
   "metadata": {
    "id": "28f4978f-7e53-4d5d-acec-671749f4e149"
   },
   "source": [
    "<p>To train the discriminator:</p>\n",
    "<ol>\n",
    "    <li>Pass the real and fake images to the discriminator</li>\n",
    "    <li>Create labels for real and fake images</li>\n",
    "    <li>Add some noise to the outputs</li>\n",
    "    <li>Calculate loss - Binary Cross Entropy</li>\n",
    "    <li>Apply backpropagation - learn</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956d2ce1-d02a-44c8-84c2-19ae1e4da0d4",
   "metadata": {
    "id": "956d2ce1-d02a-44c8-84c2-19ae1e4da0d4"
   },
   "source": [
    "<p>To train the Generator:</p>\n",
    "<ol>\n",
    "    <li>Generate some new images</li>\n",
    "    <li>Create the predicted labels</li>\n",
    "    <li>Calculate loss</li>\n",
    "    <li>Apply backpropagation - learn</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcfb4d4-686b-4902-8f17-9b7bcc91351f",
   "metadata": {
    "id": "2bcfb4d4-686b-4902-8f17-9b7bcc91351f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen_opt = Adam(learning_rate=0.0001)\n",
    "gen_loss = BinaryCrossentropy()\n",
    "\n",
    "#discriminator learning rate is set lower so it doesn't learn too fast - otherwise it would be bad for the generator\n",
    "dis_opt = Adam(learning_rate=0.00001)\n",
    "dis_loss = BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d8619c-2662-4582-a2b4-b1cd7291efe7",
   "metadata": {
    "id": "a0d8619c-2662-4582-a2b4-b1cd7291efe7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FashionGAN(Model):\n",
    "    def __init__(self, generator, discriminator, *args, **kwargs):\n",
    "        #Pass through args and kwargs to base class\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        #Create attributes for gen and dis\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "\n",
    "    def compile_model(self, gen_opt, dis_opt, gen_loss, dis_loss, *args, **kwargs):\n",
    "        #Compile with base class\n",
    "        super().compile(*args, **kwargs)\n",
    "\n",
    "        #Create attributes for losses and optimizers\n",
    "        self.gen_opt = gen_opt\n",
    "        self.gen_loss = gen_loss\n",
    "\n",
    "        self.dis_opt = dis_opt\n",
    "        self.dis_loss = dis_loss\n",
    "\n",
    "    def train_step(self, batch):\n",
    "        #Get data\n",
    "        real_imgs = batch\n",
    "        fake_imgs = self.generator(tf.random.normal((128, 128, 1)), training=False)\n",
    "\n",
    "        #Train the disriminator\n",
    "        with tf.GradientTape() as d_tape:\n",
    "            #Pass values to discriminator\n",
    "            yhat_real = self.discriminator(real_imgs, training=True)\n",
    "            yhat_fake = self.discriminator(fake_imgs, training=True)\n",
    "            yhat_realfake = tf.concat([yhat_real, yhat_fake], axis=0)\n",
    "\n",
    "            #Labels\n",
    "            y_realfake = tf.concat([tf.zeros_like(yhat_real), tf.ones_like(yhat_fake)], axis=0)\n",
    "\n",
    "            #Noise\n",
    "            noise_real = 0.15*tf.random.uniform(tf.shape(yhat_real))\n",
    "            noise_fake = -0.15*tf.random.uniform(tf.shape(yhat_fake))\n",
    "            y_realfake += tf.concat([noise_real, noise_fake], axis=0)\n",
    "\n",
    "            #Loss\n",
    "            total_dis_loss= self.dis_loss(y_realfake, yhat_realfake)\n",
    "\n",
    "        #Backpropagatioon\n",
    "        dis_grad = d_tape.gradient(total_dis_loss, self.discriminator.trainable_variables)\n",
    "        self.dis_opt.apply_gradients(zip(dis_grad, self.discriminator.trainable_variables))\n",
    "\n",
    "        #Train the generator\n",
    "        with tf.GradientTape() as g_tape:\n",
    "            #Gen Images\n",
    "            gen_images = self.generator(tf.random.normal((128, 128, 1)), training=True)\n",
    "\n",
    "            #Labels - Training set to false so ddiscriminator isn't learning while we are training the Generator\n",
    "            predicted_labels = self.discriminator(gen_images, training=False)\n",
    "\n",
    "            #Loss - real images are zeros, so we calculate how many of our predicted labels have been predicted 0\n",
    "            #since thte generated images are actually real, we reward our generator for tricking the discriminator (discriminator predicts gen image is real)\n",
    "            total_gen_loss = self.gen_loss(tf.zeros_like(predicted_labels), predicted_labels)\n",
    "\n",
    "        #Backpropagation\n",
    "        gen_grad = g_tape.gradient(total_gen_loss, self.generator.trainable_variables)\n",
    "        self.gen_opt.apply_gradients(zip(gen_grad, self.generator.trainable_variables))\n",
    "\n",
    "        return {'dis_loss': total_dis_loss, 'gen_loss': total_gen_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c86c1-9330-45a5-b6fa-6d191c619f36",
   "metadata": {
    "id": "4a1c86c1-9330-45a5-b6fa-6d191c619f36",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Instance of subclassed model\n",
    "fashgan = FashionGAN(generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e5a2ac-0c95-4386-96ca-368920692142",
   "metadata": {
    "id": "d2e5a2ac-0c95-4386-96ca-368920692142",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Compile\n",
    "fashgan.compile_model(gen_opt, dis_opt, gen_loss, dis_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28bc2c3-c6ad-4cf4-a9d2-7df7cdedc071",
   "metadata": {
    "id": "b28bc2c3-c6ad-4cf4-a9d2-7df7cdedc071",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelMonitor(Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        random_latent_vectors = tf.random.uniform((self.num_img, self.latent_dim, 1))\n",
    "        generated_images = self.model.generator(random_latent_vectors)\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range(self.num_img):\n",
    "            img = array_to_img(generated_images[i])\n",
    "            img.save(os.path.join('Fashion-GAN-images', f'generated_img_{epoch}_{i}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798fbd3-3f11-4f66-a3e6-46bda407558f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5798fbd3-3f11-4f66-a3e6-46bda407558f",
    "outputId": "cda3de9e-46bb-4afc-b74e-c9d423e48abb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Recommend 2000 epochs\n",
    "hist = fashgan.fit(data, epochs=1, callbacks=[ModelMonitor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e50d7-74ae-494a-a648-89839831efdb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "ba6e50d7-74ae-494a-a648-89839831efdb",
    "outputId": "05a73fbf-58cf-4113-a0ea-16a1c9c517f4",
    "tags": []
   },
   "outputs": [],
   "source": [
    " plt.suptitle('Loss')\n",
    " plt.plot(hist.history['dis_loss'], label='dis_loss')\n",
    " plt.plot(hist.history['gen_loss'], label='gen_loss')\n",
    " plt.legend()\n",
    " plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ak4B_vVnD-rf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "id": "ak4B_vVnD-rf",
    "outputId": "ea0bb5a5-72f2-4dae-f6bb-1930d725f04c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator.load_weights('./generatormodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a7197b-e49d-4dc1-84cd-9d27f56b34f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xQmThLVGvyu0",
   "metadata": {
    "id": "xQmThLVGvyu0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs = generator.predict(tf.random.normal((16, 128, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cT7VfvV0vyFe",
   "metadata": {
    "id": "cT7VfvV0vyFe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4, nrows=4, figsize=(20,20))\n",
    "for r in range(4):\n",
    "  for c in range(4):\n",
    "    ax[r][c].imshow(imgs[(r+1)*(c+1)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lIVxJ_x0wN_L",
   "metadata": {
    "id": "lIVxJ_x0wN_L",
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator.save('generator.h5')\n",
    "discriminator.save('discriminator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d782f7-88e5-4061-b409-f2b8e5182f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
